{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93ac104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c7f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path(\"D:\\\\Github Repos\\\\StephenKing-GPT\\\\Data\")\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7724cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in folder_path.glob(\"*.txt\"):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        texts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e387ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\\n\".join(texts)\n",
    "\n",
    "with open(\"D:\\\\Github Repos\\\\StephenKing-GPT\\\\Data\\\\input.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7984836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file back to verify\n",
    "with open(\"D:\\\\Github Repos\\\\StephenKing-GPT\\\\Data\\\\input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "590b2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of combined text: 13625328\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of combined text:\", len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76831ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To an extent this novel deals with the legal aspects of child custody in the State of Maine I asked for help in understanding this subject from my friend Warren Silver who is a fine attorney Warren guided me carefully and along the way he also told me about a quaint old device called the Stenomask which I immediately appropriated for my own fell purposes If Ive made procedural mistakes in the story which follows blame me not my legal resource Warren also asked merather plaintively if I could may\n"
     ]
    }
   ],
   "source": [
    "# first 500 characters\n",
    "print(content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "152fdbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: ['\\n', ' ', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '!', '?', '.', ',']\n",
      "Vocabulary size: 58\n"
     ]
    }
   ],
   "source": [
    "# what are all the unique characters in the text?\n",
    "chars = sorted(list(set(content)))\n",
    "chars.append(\"!\")\n",
    "chars.append(\"?\")\n",
    "chars.append(\".\")\n",
    "chars.append(\",\")\n",
    "vocab_size = len(chars)\n",
    "print(\"Unique characters:\", chars)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "260b047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String to integer mapping: {'\\n': 0, ' ': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'F': 7, 'G': 8, 'H': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'N': 15, 'O': 16, 'P': 17, 'Q': 18, 'R': 19, 'S': 20, 'T': 21, 'U': 22, 'V': 23, 'W': 24, 'X': 25, 'Y': 26, 'Z': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53, '!': 54, '?': 55, '.': 56, ',': 57}\n",
      "Integer to string mapping: {0: '\\n', 1: ' ', 2: 'A', 3: 'B', 4: 'C', 5: 'D', 6: 'E', 7: 'F', 8: 'G', 9: 'H', 10: 'I', 11: 'J', 12: 'K', 13: 'L', 14: 'M', 15: 'N', 16: 'O', 17: 'P', 18: 'Q', 19: 'R', 20: 'S', 21: 'T', 22: 'U', 23: 'V', 24: 'W', 25: 'X', 26: 'Y', 27: 'Z', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: '!', 55: '?', 56: '.', 57: ','}\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch: i for i, ch in enumerate(chars)} # create a mapping from characters to integers\n",
    "int_to_string = {i: ch for i, ch in enumerate(chars)} # create a mapping from integers to characters\n",
    "\n",
    "print(\"String to integer mapping:\", string_to_int)\n",
    "print(\"Integer to string mapping:\", int_to_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04ebb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(s):\n",
    "    return [string_to_int[ch] for ch in s]\n",
    "def decode_string(l):\n",
    "    return \"\".join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ddf9916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 32, 39, 39, 42, 57, 1, 50, 42, 45, 39, 31, 54]\n"
     ]
    }
   ],
   "source": [
    "print(encode_string(\"Hello, world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1216d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print(decode_string(encode_string(\"Hello, world!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94185def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tensor shape: torch.Size([13625328])\n",
      "Data tensor dtype: torch.int64\n",
      "First 100 elements of data tensor: tensor([21, 42,  1, 28, 41,  1, 32, 51, 47, 32, 41, 47,  1, 47, 35, 36, 46,  1,\n",
      "        41, 42, 49, 32, 39,  1, 31, 32, 28, 39, 46,  1, 50, 36, 47, 35,  1, 47,\n",
      "        35, 32,  1, 39, 32, 34, 28, 39,  1, 28, 46, 43, 32, 30, 47, 46,  1, 42,\n",
      "        33,  1, 30, 35, 36, 39, 31,  1, 30, 48, 46, 47, 42, 31, 52,  1, 36, 41,\n",
      "         1, 47, 35, 32,  1, 20, 47, 28, 47, 32,  1, 42, 33,  1, 14, 28, 36, 41,\n",
      "        32,  1, 10,  1, 28, 46, 38, 32, 31,  1])\n"
     ]
    }
   ],
   "source": [
    "# convert to datatensor\n",
    "import torch\n",
    "data = torch.tensor(encode_string(content), dtype=torch.long)\n",
    "print(\"Data tensor shape:\", data.shape)\n",
    "print(\"Data tensor dtype:\", data.dtype)\n",
    "print(\"First 100 elements of data tensor:\", data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "287ecf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([12262795])\n",
      "Validation data shape: torch.Size([1362533])\n"
     ]
    }
   ],
   "source": [
    "#split the data into train and validation sets\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f835648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 42,  1, 28, 41,  1, 32, 51, 47])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 8\n",
    "train_data[:context_length+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "085c1af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([21]) the target: 42\n",
      "when input is tensor([21, 42]) the target: 1\n",
      "when input is tensor([21, 42,  1]) the target: 28\n",
      "when input is tensor([21, 42,  1, 28]) the target: 41\n",
      "when input is tensor([21, 42,  1, 28, 41]) the target: 1\n",
      "when input is tensor([21, 42,  1, 28, 41,  1]) the target: 32\n",
      "when input is tensor([21, 42,  1, 28, 41,  1, 32]) the target: 51\n",
      "when input is tensor([21, 42,  1, 28, 41,  1, 32, 51]) the target: 47\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2c64494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 42,  1, 28, 41,  1, 32, 51])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "492af09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42,  1, 28, 41,  1, 32, 51, 47])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4167cdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is T the target: o\n",
      "when input is To the target:  \n",
      "when input is To  the target: a\n",
      "when input is To a the target: n\n",
      "when input is To an the target:  \n",
      "when input is To an  the target: e\n",
      "when input is To an e the target: x\n",
      "when input is To an ex the target: t\n"
     ]
    }
   ],
   "source": [
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {decode_string(context.tolist())} the target: {decode_string([target.item()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed50d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4 # how many sequences to process in parallel\n",
    "context_length = 8 # how many characters are included in the context\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a39dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([4, 8])\n",
      "Target batch shape: torch.Size([4, 8])\n",
      "Input batch: tensor([[35, 42, 50, 32, 45,  1, 47, 35],\n",
      "        [32,  1, 35, 28, 31,  1, 30, 45],\n",
      "        [ 1, 11, 42, 35, 41, 41, 52,  1],\n",
      "        [ 1, 36, 47,  1, 41, 32, 49, 32]])\n",
      "Target batch: tensor([[42, 50, 32, 45,  1, 47, 35, 32],\n",
      "        [ 1, 35, 28, 31,  1, 30, 45, 36],\n",
      "        [11, 42, 35, 41, 41, 52,  1, 45],\n",
      "        [36, 47,  1, 41, 32, 49, 32, 45]])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "print(\"Input batch shape:\", xb.shape)\n",
    "print(\"Target batch shape:\", yb.shape)\n",
    "print(\"Input batch:\", xb)\n",
    "print(\"Target batch:\", yb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90c655d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: 'hower th' -> Target sequence: 'ower the'\n",
      "Input sequence: 'e had cr' -> Target sequence: ' had cri'\n",
      "Input sequence: ' Johnny ' -> Target sequence: 'Johnny r'\n",
      "Input sequence: ' it neve' -> Target sequence: 'it never'\n"
     ]
    }
   ],
   "source": [
    "#decode the first batch to verify\n",
    "for i in range(batch_size):\n",
    "    input_seq = decode_string(xb[i].tolist())\n",
    "    target_seq = decode_string(yb[i].tolist())\n",
    "    print(f\"Input sequence: '{input_seq}' -> Target sequence: '{target_seq}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54637bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling tomorrow!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAM4Transport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
